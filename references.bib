%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Daniel Baker at 2024-06-30 20:50:02 +0100 


%% Saved with string encoding Unicode (UTF-8) 



@article{Hong2022,
	abstract = {A socially consequential test of the cognitive penetrability of visual perception is whether merely sharing a group membership with another person influences how you encode their face. Past research has examined this issue by manipulating group membership with techniques from social psychology and then measuring the face-sensitive N170 ERP. However, methodological differences across studies make it difficult to draw conclusions from this literature. In our research, we conducted two large-scale, preregistered ERP studies to address how critical methodological decisions could influence conclusions about top-down effects of group membership on face perception. Specifically, we examined how mere group membership, perceptual markers that signify group membership, number of trials included in the study design, the racial/ethnic identity of face stimuli, and the data analytic approach affect inferences about the N170 response to faces. In Study 1, we found no evidence that mere group membership significantly influenced the N170. However, we found that the background color used to signify group membership modulated the magnitude and latency of the N170. Exploratory analyses also showed effects of stimulus race/ethnicity. In Study 2, we dissociated background color from face encoding by presenting background color before the faces. In this second study, we found no main effect of group membership, background color, or stimulus race/ethnicity. However, we did see an unhypothesized mere group membership effect on trials toward the end of the study. Our results inform debates about social categorization effects on visual perception and show how bottom-up indicators of group membership can bias face encoding.},
	author = {Hong, Youngki and Mayes, Matthew S and Munasinghe, Anudhi P and Ratner, Kyle G},
	date-added = {2024-06-30 20:49:56 +0100},
	date-modified = {2024-06-30 20:49:56 +0100},
	doi = {10.1162/jocn_a_01887},
	journal = {J Cogn Neurosci},
	journal-full = {Journal of cognitive neuroscience},
	mesh = {Electroencephalography; Evoked Potentials; Face; Group Processes; Humans; Photic Stimulation},
	month = {Oct},
	number = {11},
	pages = {1999-2015},
	pmid = {35802591},
	pst = {ppublish},
	title = {Scrutinizing Whether Mere Group Membership Influences the N170 Response to Faces: Results from Two Preregistered Event-Related Potential Studies},
	volume = {34},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1162/jocn_a_01887}}

@article{Geiger2021,
	abstract = {Face recognition is supported by selective neural mechanisms that are sensitive to various aspects of facial appearance. These include event-related potential (ERP) components like the P100 and the N170 which exhibit different patterns of selectivity for various aspects of facial appearance. Examining the boundary between faces and non-faces using these responses is one way to develop a more robust understanding of the representation of faces in extrastriate cortex and determine what critical properties an image must possess to be considered face-like. Robot faces are a particularly interesting stimulus class to examine because they can differ markedly from human faces in terms of shape, surface properties, and the configuration of facial features, but are also interpreted as social agents in a range of settings. In the current study, we thus chose to investigate how ERP responses to robot faces may differ from the response to human faces and non-face objects. In two experiments, we examined how the P100 and N170 responded to human faces, robot faces, and non-face objects (clocks). In Experiment 1, we found that robot faces elicit intermediate responses from face-sensitive components relative to non-face objects (clocks) and both real human faces and artificial human faces (computer-generated faces and dolls). These results suggest that while human-like inanimate faces (CG faces and dolls) are processed much like real faces, robot faces are dissimilar enough to human faces to be processed differently. In Experiment 2 we found that the face inversion effect was only partly evident in robot faces. We conclude that robot faces are an intermediate stimulus class that offers insight into the perceptual and cognitive factors that affect how social agents are identified and categorized.},
	author = {Geiger, Allie R and Balas, Benjamin},
	date-added = {2024-06-30 20:49:46 +0100},
	date-modified = {2024-06-30 20:49:46 +0100},
	doi = {10.1038/s41598-021-97527-6},
	journal = {Sci Rep},
	journal-full = {Scientific reports},
	month = {Sep},
	number = {1},
	pages = {17890},
	pmc = {PMC8429544},
	pmid = {34504241},
	pst = {epublish},
	title = {Robot faces elicit responses intermediate to human faces and objects at face-sensitive ERP components},
	volume = {11},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1038/s41598-021-97527-6}}

@article{Koverola2022,
	abstract = {Psychometric scales are useful tools in understanding people's attitudes towards different aspects of life. As societies develop and new technologies arise, new validated scales are needed. Robots and artificial intelligences of various kinds are about to occupy just about every niche in human society. Several tools to measure fears and anxieties about robots do exist, but there is a definite lack of tools to measure hopes and expectations for these new technologies. Here, we create and validate a novel multi-dimensional scale which measures people's attitudes towards robots, giving equal weight to positive and negative attitudes. Our scale differentiates (a) comfort and enjoyment around robots, (b) unease and anxiety around robots, (c) rational hopes about robots in general (at societal level) and (d) rational worries about robots in general (at societal level). The scale was developed by extracting items from previous scales, crowdsourcing new items, testing through 3 scale iterations by exploratory factor analysis (Ns 135, 801 and 609) and validated in its final form of the scale by confirmatory factor analysis (N: 477). We hope our scale will be a useful instrument for social scientists who wish to study human-technology relations with a validated scale in efficient and generalizable ways.},
	author = {Koverola, Mika and Kunnari, Anton and Sundvall, Jukka and Laakasuo, Michael},
	date-added = {2024-06-25 20:33:15 +0100},
	date-modified = {2024-06-25 20:33:15 +0100},
	day = {01},
	doi = {10.1007/s12369-022-00880-3},
	issn = {1875-4805},
	journal = {International Journal of Social Robotics},
	month = {Sep},
	number = {7},
	pages = {1559--1581},
	title = {General Attitudes Towards Robots Scale (GAToRS): A New Instrument for Social Surveys},
	url = {https://link.springer.com/content/pdf/10.1007/s12369-022-00880-3.pdf},
	volume = {14},
	year = {2022},
	bdsk-url-1 = {https://link.springer.com/content/pdf/10.1007/s12369-022-00880-3.pdf},
	bdsk-url-2 = {https://doi.org/10.1007/s12369-022-00880-3}}

@article{Bartneck2009,
	abstract = {This study emphasizes the need for standardized measurement tools for human robot interaction (HRI). If we are to make progress in this field then we must be able to compare the results from different studies. A{\^A} literature review has been performed on the measurements of five key concepts in HRI: anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety. The results have been distilled into five consistent questionnaires using semantic differential scales. We report reliability and validity indicators based on several empirical studies that used these questionnaires. It is our hope that these questionnaires can be used by robot developers to monitor their progress. Psychologists are invited to further develop the questionnaires by adding new concepts, and to conduct further validations where it appears necessary.},
	author = {Bartneck, Christoph and Kuli{\'{c}}, Dana and Croft, Elizabeth and Zoghbi, Susana},
	date-added = {2024-06-25 20:32:45 +0100},
	date-modified = {2024-06-25 20:32:45 +0100},
	day = {01},
	doi = {10.1007/s12369-008-0001-3},
	issn = {1875-4805},
	journal = {International Journal of Social Robotics},
	month = {Jan},
	number = {1},
	pages = {71--81},
	title = {Measurement Instruments for the Anthropomorphism, Animacy, Likeability, Perceived Intelligence, and Perceived Safety of Robots},
	url = {https://link.springer.com/content/pdf/10.1007/s12369-008-0001-3.pdf},
	volume = {1},
	year = {2009},
	bdsk-url-1 = {https://link.springer.com/content/pdf/10.1007/s12369-008-0001-3.pdf},
	bdsk-url-2 = {https://doi.org/10.1007/s12369-008-0001-3}}

@article{Baron-Cohen2001,
	abstract = {Currently there are no brief, self-administered instruments for measuring the degree to which an adult with normal intelligence has the traits associated with the autistic spectrum. In this paper, we report on a new instrument to assess this: the Autism-Spectrum Quotient (AQ). Individuals score in the range 0-50. Four groups of subjects were assessed: Group 1: 58 adults with Asperger syndrome (AS) or high-functioning autism (HFA); Group 2: 174 randomly selected controls. Group 3: 840 students in Cambridge University; and Group 4: 16 winners of the UK Mathematics Olympiad. The adults with AS/HFA had a mean AQ score of 35.8 (SD = 6.5), significantly higher than Group 2 controls (M = 16.4, SD = 6.3). 80% of the adults with AS/HFA scored 32+, versus 2% of controls. Among the controls, men scored slightly but significantly higher than women. No women scored extremely highly (AQ score 34+) whereas 4% of men did so. Twice as many men (40%) as women (21%) scored at intermediate levels (AQ score 20+). Among the AS/HFA group, male and female scores did not differ significantly. The students in Cambridge University did not differ from the randomly selected control group, but scientists (including mathematicians) scored significantly higher than both humanities and social sciences students, confirming an earlier study that autistic conditions are associated with scientific skills. Within the sciences, mathematicians scored highest. This was replicated in Group 4, the Mathematics Olympiad winners scoring significantly higher than the male Cambridge humanities students. 6% of the student sample scored 32+ on the AQ. On interview, 11 out of 11 of these met three or more DSM-IV criteria for AS/HFA, and all were studying sciences/mathematics, and 7 of the 11 met threshold on these criteria. Test-retest and interrater reliability of the AQ was good. The AQ is thus a valuable instrument for rapidly quantifying where any given individual is situated on the continuum from autism to normality. Its potential for screening for autism spectrum conditions in adults of normal intelligence remains to be fully explored.},
	author = {Baron-Cohen, S and Wheelwright, S and Skinner, R and Martin, J and Clubley, E},
	date-added = {2024-06-25 20:32:42 +0100},
	date-modified = {2024-06-25 20:32:42 +0100},
	doi = {10.1023/a:1005653411471},
	journal = {J Autism Dev Disord},
	journal-full = {Journal of autism and developmental disorders},
	mesh = {Adult; Asperger Syndrome; Autistic Disorder; Diagnosis, Differential; England; Female; Humans; Intelligence; Male; Personality Assessment; Personality Inventory; Psychometrics; Reproducibility of Results; Students},
	month = {Feb},
	number = {1},
	pages = {5-17},
	pmid = {11439754},
	pst = {ppublish},
	title = {The autism-spectrum quotient (AQ): evidence from Asperger syndrome/high-functioning autism, males and females, scientists and mathematicians},
	volume = {31},
	year = {2001},
	bdsk-url-1 = {https://doi.org/10.1023/a:1005653411471}}

@article{Robertson2024,
	author = {Robertson, David J and Davis, J.P. and Sanders, Jet Gabrielle and Towler, A.},
	date-added = {2024-06-25 08:05:22 +0100},
	date-modified = {2024-06-25 08:06:56 +0100},
	doi = {10.31234/osf.io/u2kja},
	journal = {in press},
	title = {The super-recogniser advantage extends to the detection of hyper-realistic face masks},
	year = {2024},
	bdsk-url-1 = {https://doi.org/10.31234/osf.io/u2kja}}

@incollection{Sanders2021,
	abstract = {{Security and crime prevention often rely on facial appearance to connect individuals to behaviours. Hyper-realistic face masks can potentially frustrate this connection by allowing the wearer to look like someone else. In this chapter, we review the evidence that hyper-realistic masks are truly realistic, in the sense that they are accepted as real faces. We begin by outlining relevant experimental studies of face identification and disguise. We then tabulate all criminal cases known to involve hyper-realistic face masks (41 cases between 2009 and 2019). Experimental tests suggest that failures to detect such masks can be attributed to the realism of the masks, without invoking inattention or incompetence on the part of observers. We end with eight proposals for improving mask detection, encompassing training, personnel selection, and machine vision. If the misuse of hyper-realistic masks becomes widespread, our inability to detect them will compromise face recognition infrastructure.}},
	author = {Sanders, Jet G. and Jenkins, Rob},
	booktitle = {{Forensic Face Matching: Research and Practice}},
	date-added = {2024-06-24 06:45:41 +0100},
	date-modified = {2024-06-24 06:46:18 +0100},
	doi = {10.1093/oso/9780198837749.003.0010},
	editor = {Bindemann, M.},
	eprint = {https://academic.oup.com/book/0/chapter/339639372/chapter-pdf/57818540/oso-9780198837749-chapter-10.pdf},
	isbn = {9780198837749},
	month = {01},
	publisher = {Oxford University Press},
	title = {Realistic Masks in the Real World},
	url = {https://doi.org/10.1093/oso/9780198837749.003.0010},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1093/oso/9780198837749.003.0010}}

@article{Sanders2019,
	abstract = {BACKGROUND: Recent experimental work has shown that hyper-realistic face masks can pass for real faces during live viewing. However, live viewing embeds the perceptual task (mask detection) in a powerful social context that may influence respondents' behaviour. To remove this social context, we assessed viewers' ability to distinguish photos of hyper-realistic masks from photos of real faces in a computerised two-alternative forced choice (2AFC) procedure.
RESULTS: In experiment 1 (N = 120), we observed an error rate of 33% when viewing time was restricted to 500 ms. In experiment 2 (N = 120), we observed an error rate of 20% when viewing time was unlimited. In both experiments we saw a significant performance cost for other-race comparisons relative to own-race comparisons.
CONCLUSIONS: We conclude that viewers could not reliably distinguish hyper-realistic face masks from real faces in photographic presentations. As well as its theoretical interest, failure to detect synthetic faces has important implications for security and crime prevention, which often rely on facial appearance and personal identity being related.},
	author = {Sanders, Jet Gabrielle and Ueda, Yoshiyuki and Yoshikawa, Sakiko and Jenkins, Rob},
	date-added = {2024-06-24 06:44:53 +0100},
	date-modified = {2024-06-24 06:44:53 +0100},
	doi = {10.1186/s41235-019-0197-9},
	journal = {Cogn Res Princ Implic},
	journal-full = {Cognitive research: principles and implications},
	keywords = {2AFC; Deliberate disguise; Hyper-realistic face masks; Other-race effect; Silicone masks; Synthetic faces; Turing test},
	month = {Nov},
	number = {1},
	pages = {43},
	pmc = {PMC6868074},
	pmid = {31748844},
	pst = {epublish},
	title = {More human than human: a Turing test for photographed faces},
	volume = {4},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1186/s41235-019-0197-9}}

@article{Robertson2020,
	abstract = {Hyper-realistic face masks have been used as disguises in at least one border crossing and in numerous criminal cases. Experimental tests using these masks have shown that viewers accept them as real faces under a range of conditions. Here, we tested mask detection in a live identity verification task. Fifty-four visitors at the London Science Museum viewed a mask wearer at close range (2 m) as part of a mock passport check. They then answered a series of questions designed to assess mask detection, while the masked traveller was still in view. In the identity matching task, 8% of viewers accepted the mask as matching a real photo of someone else, and 82% accepted the match between masked person and masked photo. When asked if there was any reason to detain the traveller, only 13% of viewers mentioned a mask. A further 11% picked disguise from a list of suggested reasons. Even after reading about mask-related fraud, 10% of viewers judged that the traveller was not wearing a mask. Overall, mask detection was poor and was not predicted by unfamiliar face matching performance. We conclude that hyper-realistic face masks could go undetected during live identity checks.},
	author = {Robertson, David J and Sanders, Jet G and Towler, Alice and Kramer, Robin S S and Spowage, Josh and Byrne, Ailish and Burton, A Mike and Jenkins, Rob},
	date-added = {2024-05-23 06:08:26 +0100},
	date-modified = {2024-05-23 06:08:26 +0100},
	doi = {10.1177/0301006620904614},
	journal = {Perception},
	journal-full = {Perception},
	keywords = {deception; face perception; face recognition; fraud; identification; masks; passports; realistic; silicone},
	mesh = {Adolescent; Adult; Deception; Face; Facial Recognition; Female; Humans; Male; Masks; Middle Aged; Silicones; Social Perception; Young Adult},
	month = {Mar},
	number = {3},
	pages = {298-309},
	pmc = {PMC7583446},
	pmid = {32013720},
	pst = {ppublish},
	title = {Hyper-realistic Face Masks in a Live Passport-Checking Task},
	volume = {49},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1177/0301006620904614}}

@article{Coggan2016,
	abstract = {Brain-imaging studies have found distinct spatial and temporal patterns of response to different object categories across the brain. However, the extent to which these categorical patterns of response reflect higher-level semantic or lower-level visual properties of the stimulus remains unclear. To address this question, we measured patterns of EEG response to intact and scrambled images in the human brain. Our rationale for using scrambled images is that they have many of the visual properties found in intact images, but do not convey any semantic information. Images from different object categories (bottle, face, house) were briefly presented (400 ms) in an event-related design. A multivariate pattern analysis revealed categorical patterns of response to intact images emerged ∼80-100 ms after stimulus onset and were still evident when the stimulus was no longer present (∼800 ms). Next, we measured the patterns of response to scrambled images. Categorical patterns of response to scrambled images also emerged ∼80-100 ms after stimulus onset. However, in contrast to the intact images, distinct patterns of response to scrambled images were mostly evident while the stimulus was present (∼400 ms). Moreover, scrambled images were able to account only for all the variance in the intact images at early stages of processing. This direct manipulation of visual and semantic content provides new insights into the temporal dynamics of object perception and the extent to which different stages of processing are dependent on lower-level or higher-level properties of the image.},
	author = {Coggan, David D and Baker, Daniel H and Andrews, Timothy J},
	date-added = {2024-05-23 06:03:39 +0100},
	date-modified = {2024-05-23 06:03:39 +0100},
	doi = {10.1523/ENEURO.0158-16.2016},
	journal = {eNeuro},
	journal-full = {eNeuro},
	keywords = {EEG; MVPA; category; image; object},
	mesh = {Brain; Electroencephalography; Female; Humans; Male; Multivariate Analysis; Photic Stimulation; Semantics; Visual Perception; Young Adult},
	number = {4},
	pmc = {PMC4967817},
	pmid = {27517086},
	pst = {epublish},
	title = {The Role of Visual and Semantic Properties in the Emergence of Category-Specific Patterns of Neural Response in the Human Brain},
	volume = {3},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1523/ENEURO.0158-16.2016}}

@article{Cheetham2015,
	abstract = {The main prediction of the Uncanny Valley Hypothesis (UVH) is that observation of humanlike characters that are difficult to distinguish from the human counterpart will evoke a state of negative affect. Well-established electrophysiological [late positive potential (LPP) and facial electromyography (EMG)] and self-report [Self-Assessment Manikin (SAM)] indices of valence and arousal, i.e., the primary orthogonal dimensions of affective experience, were used to test this prediction by examining affective experience in response to categorically ambiguous compared with unambiguous avatar and human faces (N = 30). LPP and EMG provided direct psychophysiological indices of affective state during passive observation and the SAM provided self-reported indices of affective state during explicit cognitive evaluation of static facial stimuli. The faces were drawn from well-controlled morph continua representing the UVH' dimension of human likeness (DHL). The results provide no support for the notion that category ambiguity along the DHL is specifically associated with enhanced experience of negative affect. On the contrary, the LPP and SAM-based measures of arousal and valence indicated a general increase in negative affective state (i.e., enhanced arousal and negative valence) with greater morph distance from the human end of the DHL. A second sample (N = 30) produced the same finding, using an ad hoc self-rating scale of feelings of familiarity, i.e., an oft-used measure of affective experience along the UVH' familiarity dimension. In conclusion, this multi-method approach using well-validated psychophysiological and self-rating indices of arousal and valence rejects - for passive observation and for explicit affective evaluation of static faces - the main prediction of the UVH.},
	author = {Cheetham, Marcus and Wu, Lingdan and Pauli, Paul and Jancke, Lutz},
	date-added = {2024-05-22 20:19:57 +0100},
	date-modified = {2024-05-22 20:19:57 +0100},
	doi = {10.3389/fpsyg.2015.00981},
	journal = {Front Psychol},
	journal-full = {Frontiers in psychology},
	keywords = {EEG; EMG; LPP; arousal; familiarity; uncanny valley hypothesis; valence},
	pages = {981},
	pmc = {PMC4502535},
	pmid = {26236260},
	pst = {epublish},
	title = {Arousal, valence, and the uncanny valley: psychophysiological and self-report findings},
	volume = {6},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.3389/fpsyg.2015.00981}}

@inproceedings{Mustafa2017,
	author = {Mustafa, Maryam and Guthe, Stefan and Tauscher, Jan-Philipp and Goesele, Michael and Magnor, Marcus},
	booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
	collection = {CHI {\^a}17},
	date-added = {2024-05-22 20:19:20 +0100},
	date-modified = {2024-05-22 20:29:16 +0100},
	doi = {10.1145/3025453.3026043},
	month = may,
	publisher = {ACM},
	series = {CHI 17},
	title = {How Human Am I?: EEG-based Evaluation of Virtual Characters},
	url = {http://dx.doi.org/10.1145/3025453.3026043},
	year = {2017},
	bdsk-url-1 = {http://dx.doi.org/10.1145/3025453.3026043}}

@inproceedings{Mustafa2016,
	author = {Mustafa, Maryam and Magnor, Marcus},
	booktitle = {Proceedings of the 13th European Conference on Visual Media Production (CVMP 2016)},
	collection = {CVMP 2016},
	date-added = {2024-05-22 20:10:51 +0100},
	date-modified = {2024-05-22 20:30:44 +0100},
	doi = {10.1145/2998559.2998563},
	month = dec,
	publisher = {ACM},
	series = {CVMP 2016},
	title = {EEG Based Analysis of the Perception of Computer-Generated Faces.},
	url = {http://dx.doi.org/10.1145/2998559.2998563},
	year = {2016},
	bdsk-url-1 = {http://dx.doi.org/10.1145/2998559.2998563}}

@article{Schindler2017,
	abstract = {Cartoon characters are omnipresent in popular media. While few studies have scientifically investigated their processing, in computer graphics, efforts are made to increase realism. Yet, close approximations of reality have been suggested to evoke sometimes a feeling of eeriness, the "uncanny valley" effect. Here, we used high-density electroencephalography to investigate brain responses to professionally stylized happy, angry, and neutral character faces. We employed six face-stylization levels varying from abstract to realistic and investigated the N170, early posterior negativity (EPN), and late positive potential (LPP) event-related components. The face-specific N170 showed a u-shaped modulation, with stronger reactions towards both most abstract and most realistic compared to medium-stylized faces. For abstract faces, N170 was generated more occipitally than for real faces, implying stronger reliance on structural processing. Although emotional faces elicited highest amplitudes on both N170 and EPN, on the N170 realism and expression interacted. Finally, LPP increased linearly with face realism, reflecting activity increase in visual and parietal cortex for more realistic faces. Results reveal differential effects of face stylization on distinct face processing stages and suggest a perceptual basis to the uncanny valley hypothesis. They are discussed in relation to face perception, media design, and computer graphics.},
	author = {Schindler, Sebastian and Zell, Eduard and Botsch, Mario and Kissler, Johanna},
	date-added = {2024-05-22 20:09:25 +0100},
	date-modified = {2024-05-22 20:09:25 +0100},
	doi = {10.1038/srep45003},
	journal = {Sci Rep},
	journal-full = {Scientific reports},
	mesh = {Adult; Brain; Electroencephalography; Electrophysiological Phenomena; Emotions; Evoked Potentials; Facial Expression; Facial Recognition; Female; Humans; Male; Models, Biological; Photic Stimulation; Reaction Time; Young Adult},
	month = {Mar},
	pages = {45003},
	pmc = {PMC5362933},
	pmid = {28332557},
	pst = {epublish},
	title = {Differential effects of face-realism and emotion on event-related brain potentials and their implications for the uncanny valley theory},
	volume = {7},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1038/srep45003}}

@article{Rosenthal2019,
	abstract = {Artificial agents are becoming prevalent across human life domains. However, the neural mechanisms underlying human responses to these new, artificial social partners remain unclear. The uncanny valley (UV) hypothesis predicts that humans prefer anthropomorphic agents but reject them if they become too humanlike-the so-called UV reaction. Using fMRI, we investigated neural activity when subjects evaluated artificial agents and made decisions about them. Across two experimental tasks, the ventromedial prefrontal cortex (VMPFC) encoded an explicit representation of subjects' UV reactions. Specifically, VMPFC signaled the subjective likability of artificial agents as a nonlinear function of humanlikeness, with selective low likability for highly humanlike agents. In exploratory across-subject analyses, these effects explained individual differences in psychophysical evaluations and preference choices. Functionally connected areas encoded critical inputs for these signals: the temporoparietal junction encoded a linear humanlikeness continuum, whereas nonlinear representations of humanlikeness in dorsomedial prefrontal cortex (DMPFC) and fusiform gyrus emphasized a human-nonhuman distinction. Following principles of multisensory integration, multiplicative combination of these signals reconstructed VMPFC's valuation function. During decision making, separate signals in VMPFC and DMPFC encoded subjects' decision variable for choices involving humans or artificial agents, respectively. A distinct amygdala signal predicted rejection of artificial agents. Our data suggest that human reactions toward artificial agents are governed by a neural mechanism that generates a selective, nonlinear valuation in response to a specific feature combination (humanlikeness in nonhuman agents). Thus, a basic principle known from sensory coding-neural feature selectivity from linear-nonlinear transformation-may also underlie human responses to artificial social partners.SIGNIFICANCE STATEMENT Would you trust a robot to make decisions for you? Autonomous artificial agents are increasingly entering our lives, but how the human brain responds to these new artificial social partners remains unclear. The uncanny valley (UV) hypothesis-an influential psychological framework-captures the observation that human responses to artificial agents are nonlinear: we like increasingly anthropomorphic artificial agents, but feel uncomfortable if they become too humanlike. Here we investigated neural activity when humans evaluated artificial agents and made personal decisions about them. Our findings suggest a novel neurobiological conceptualization of human responses toward artificial agents: the UV reaction-a selective dislike of highly humanlike agents-is based on nonlinear value-coding in ventromedial prefrontal cortex, a key component of the brain's reward system.},
	author = {Rosenthal-von der P{\"u}tten, Astrid M and Kr{\"a}mer, Nicole C and Maderwald, Stefan and Brand, Matthias and Grabenhorst, Fabian},
	date-added = {2024-04-21 20:28:44 +0100},
	date-modified = {2024-04-21 20:28:57 +0100},
	doi = {10.1523/JNEUROSCI.2956-18.2019},
	journal = {J Neurosci},
	journal-full = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	keywords = {emotion; mentalizing; prefrontal cortex; reward; social},
	mesh = {Adolescent; Adult; Artificial Intelligence; Choice Behavior; Female; Humans; Magnetic Resonance Imaging; Male; Mentalization; Prefrontal Cortex; Psychological Distance; Robotics; Young Adult},
	month = {Aug},
	number = {33},
	pages = {6555-6570},
	pmc = {PMC6697392},
	pmid = {31263064},
	pst = {ppublish},
	title = {Neural Mechanisms for Accepting and Rejecting Artificial Social Partners in the Uncanny Valley},
	volume = {39},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1523/JNEUROSCI.2956-18.2019}}

@article{Chen2024,
	abstract = {Artificially created human faces play an increasingly important role in our digital world. However, the so-called uncanny valley effect may cause people to perceive highly, yet not perfectly human-like faces as eerie, bringing challenges to the interaction with virtual agents. At the same time, the neurocognitive underpinnings of the uncanny valley effect remain elusive. Here, we utilized an electroencephalography (EEG) dataset of steady-state visual evoked potentials (SSVEP) in which participants were presented with human face images of different stylization levels ranging from simplistic cartoons to actual photographs. Assessing neuronal responses both in frequency and time domain, we found a non-linear relationship between SSVEP amplitudes and stylization level, that is, the most stylized cartoon images and the real photographs evoked stronger responses than images with medium stylization. Moreover, realness of even highly similar stylization levels could be decoded from the EEG data with task-related component analysis (TRCA). Importantly, we also account for confounding factors, such as the size of the stimulus face's eyes, which previously have not been adequately addressed. Together, this study provides a basis for future research and neuronal benchmarking of real-time detection of face realness regarding three aspects: SSVEP-based neural markers, efficient classification methods, and low-level stimulus confounders.},
	author = {Chen, Yonghao and Stephani, Tilman and Bagdasarian, Milena Teresa and Hilsmann, Anna and Eisert, Peter and Villringer, Arno and Bosse, Sebastian and Gaebler, Michael and Nikulin, Vadim V},
	date-added = {2024-04-21 20:25:55 +0100},
	date-modified = {2024-04-21 20:25:55 +0100},
	doi = {10.1038/s41598-024-56130-1},
	journal = {Sci Rep},
	journal-full = {Scientific reports},
	mesh = {Humans; Evoked Potentials, Visual; Electroencephalography; Eye; Neurologic Examination; Photic Stimulation; Brain-Computer Interfaces},
	month = {Mar},
	number = {1},
	pages = {5683},
	pmc = {PMC10920746},
	pmid = {38454099},
	pst = {epublish},
	title = {Realness of face images can be decoded from non-linear modulation of EEG responses},
	volume = {14},
	year = {2024},
	bdsk-url-1 = {https://doi.org/10.1038/s41598-024-56130-1}}

@article{Gorlini2023,
	abstract = {The Uncanny Valley phenomenon refers to the feeling of unease that arises when interacting with characters that appear almost, but not quite, human-like. First theorised by Masahiro Mori in 1970, it has since been widely observed in different contexts from humanoid robots to video games, in which it can result in players feeling uncomfortable or disconnected from the game, leading to a lack of immersion and potentially reducing the overall enjoyment. The phenomenon has been observed and described mostly through behavioural studies based on self-reported scales of uncanny feeling: however, there is still no consensus on its cognitive and perceptual origins, which limits our understanding of its impact on player experience. In this paper, we present a study aimed at identifying the mechanisms that trigger the uncanny response by collecting and analysing both self-reported feedback and EEG data.},
	author = {Chiara Gorlini and Laurits Dixen and Paolo Burelli},
	date-added = {2024-04-21 20:24:59 +0100},
	date-modified = {2024-04-21 20:25:12 +0100},
	eprint = {2306.16233},
	journal = {arXiv},
	month = {06},
	title = {Investigating the Uncanny Valley Phenomenon Through the Temporal Dynamics of Neural Responses to Virtual Characters},
	url = {https://arxiv.org/pdf/2306.16233.pdf},
	year = {2023},
	bdsk-url-1 = {https://arxiv.org/pdf/2306.16233.pdf},
	bdsk-url-2 = {https://arxiv.org/abs/2306.16233}}

@article{Vaitonyte2023,
	abstract = {The Uncanny Valley (UV) theory predicts that imperfectly human-like artificial agents elicit negative reactions in perceivers. While to date most studies investigating the UV have been behavioral, there is a growing number of neuroscientific studies that hold the potential of shedding light on the automatic processes related to the UV. The current paper provides a scoping review of studies using brain imaging techniques that addressed the UV. Of the total of 74 studies found in the database search, 13 met the inclusion criteria and compared the neural processing of human vs. artificial agent stimuli. Neural differences were found when processing the faces of humans and artificial agents, with reduced responses for the latter in a face-selective brain region, the fusiform face area. At the temporal level, specific event-related potential (ERP) components were susceptible to facial appearance, such as the Late Positive Potential. The studies that employed mentalizing, i.e., reasoning about other agents' behavior, showed that different brain regions of the mentalizing network were engaged, with the temporo-parietal junction being more responsive to humans, while the ventromedial prefrontal cortex and the precuneus were more responsive when reasoning about artificial agents. Some commonalities were also observed: the processing of human and artificial agent actions activated comparable brain areas in the sensorimotor cortex. Not only does this scoping review shed light on the neural processes that may underlie the UV, but it also allows for generating predictions with respect to processing differences regarding human and artificial agents.},
	author = {Julija Vaitonyt{\.e} and Maryam Alimardani and Max M. Louwerse},
	date-added = {2024-04-21 20:18:55 +0100},
	date-modified = {2024-04-21 20:19:08 +0100},
	doi = {https://doi.org/10.1016/j.chbr.2022.100263},
	issn = {2451-9588},
	journal = {Computers in Human Behavior Reports},
	keywords = {Uncanny valley, Neuroscience, Social perception, Face processing, Artificial agents},
	pages = {100263},
	title = {Scoping review of the neural evidence on the uncanny valley},
	url = {https://www.sciencedirect.com/science/article/pii/S2451958822000975},
	volume = {9},
	year = {2023},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S2451958822000975},
	bdsk-url-2 = {https://doi.org/10.1016/j.chbr.2022.100263}}

@book{Macmillan2005,
	author = {Macmillan, N.A. and Creelman, C.D.},
	date-added = {2023-02-14 07:30:12 +0000},
	date-modified = {2023-02-14 07:30:45 +0000},
	publisher = {Psychology Press},
	title = {Detection theory: a user's guide},
	year = {2005}}

@article{Chang2011,
	author = {Chang, C.-C. and Lin, C.-J.},
	date-added = {2023-02-14 07:09:14 +0000},
	date-modified = {2023-02-14 07:10:47 +0000},
	journal = {ACM Transactions on Intelligent Systems and Technology},
	pages = {1-27},
	title = {{LIBSVM} : a library for support vector machines},
	volume = {2(27)},
	year = {2011}}

@article{Tadel2011,
	abstract = {Brainstorm is a collaborative open-source application dedicated to magnetoencephalography (MEG) and electroencephalography (EEG) data visualization and processing, with an emphasis on cortical source estimation techniques and their integration with anatomical magnetic resonance imaging (MRI) data. The primary objective of the software is to connect MEG/EEG neuroscience investigators with both the best-established and cutting-edge methods through a simple and intuitive graphical user interface (GUI).},
	author = {Tadel, Fran{\c c}ois and Baillet, Sylvain and Mosher, John C and Pantazis, Dimitrios and Leahy, Richard M},
	date-added = {2023-02-07 17:54:29 +0000},
	date-modified = {2023-02-07 17:54:29 +0000},
	doi = {10.1155/2011/879716},
	journal = {Comput Intell Neurosci},
	journal-full = {Computational intelligence and neuroscience},
	mesh = {Animals; Brain; Brain Mapping; Brain Waves; Computer Graphics; Electroencephalography; Electronic Data Processing; Humans; Magnetic Resonance Imaging; Magnetoencephalography; Models, Neurological; Software; Time Factors; User-Computer Interface},
	pages = {879716},
	pmc = {PMC3090754},
	pmid = {21584256},
	pst = {ppublish},
	title = {Brainstorm: a user-friendly application for MEG/EEG analysis},
	volume = {2011},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.1155/2011/879716}}

@article{Delorme2004,
	abstract = {We have developed a toolbox and graphic user interface, EEGLAB, running under the crossplatform MATLAB environment (The Mathworks, Inc.) for processing collections of single-trial and/or averaged EEG data of any number of channels. Available functions include EEG data, channel and event information importing, data visualization (scrolling, scalp map and dipole model plotting, plus multi-trial ERP-image plots), preprocessing (including artifact rejection, filtering, epoch selection, and averaging), independent component analysis (ICA) and time/frequency decompositions including channel and component cross-coherence supported by bootstrap statistical methods based on data resampling. EEGLAB functions are organized into three layers. Top-layer functions allow users to interact with the data through the graphic interface without needing to use MATLAB syntax. Menu options allow users to tune the behavior of EEGLAB to available memory. Middle-layer functions allow users to customize data processing using command history and interactive 'pop' functions. Experienced MATLAB users can use EEGLAB data structures and stand-alone signal processing functions to write custom and/or batch analysis scripts. Extensive function help and tutorial information are included. A 'plug-in' facility allows easy incorporation of new EEG modules into the main menu. EEGLAB is freely available (http://www.sccn.ucsd.edu/eeglab/) under the GNU public license for noncommercial use and open source development, together with sample data, user tutorial and extensive documentation.},
	author = {Delorme, Arnaud and Makeig, Scott},
	date-added = {2022-12-30 18:26:29 +0000},
	date-modified = {2022-12-30 18:26:29 +0000},
	doi = {10.1016/j.jneumeth.2003.10.009},
	journal = {J Neurosci Methods},
	journal-full = {Journal of neuroscience methods},
	mesh = {Computer Simulation; Electroencephalography; Evoked Potentials; Software},
	month = {Mar},
	number = {1},
	pages = {9-21},
	pmid = {15102499},
	pst = {ppublish},
	title = {{EEGLAB}: an open source toolbox for analysis of single-trial {EEG} dynamics including independent component analysis},
	volume = {134},
	year = {2004},
	bdsk-url-1 = {https://doi.org/10.1016/j.jneumeth.2003.10.009}}

@article{Saygin2012,
	abstract = {Using functional magnetic resonance imaging (fMRI) repetition suppression, we explored the selectivity of the human action perception system (APS), which consists of temporal, parietal and frontal areas, for the appearance and/or motion of the perceived agent. Participants watched body movements of a human (biological appearance and movement), a robot (mechanical appearance and movement) or an android (biological appearance, mechanical movement). With the exception of extrastriate body area, which showed more suppression for human like appearance, the APS was not selective for appearance or motion per se. Instead, distinctive responses were found to the mismatch between appearance and motion: whereas suppression effects for the human and robot were similar to each other, they were stronger for the android, notably in bilateral anterior intraparietal sulcus, a key node in the APS. These results could reflect increased prediction error as the brain negotiates an agent that appears human, but does not move biologically, and help explain the 'uncanny valley' phenomenon.},
	author = {Saygin, Ayse Pinar and Chaminade, Thierry and Ishiguro, Hiroshi and Driver, Jon and Frith, Chris},
	date-added = {2022-12-29 10:58:24 +0000},
	date-modified = {2022-12-29 10:58:24 +0000},
	doi = {10.1093/scan/nsr025},
	journal = {Soc Cogn Affect Neurosci},
	journal-full = {Social cognitive and affective neuroscience},
	mesh = {Adult; Biomechanical Phenomena; Brain Mapping; Cerebral Cortex; Eye Movements; Female; Gestures; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Motion; Motion Perception; Oxygen; Photic Stimulation; Predictive Value of Tests; Random Allocation; Robotics; Young Adult},
	month = {Apr},
	number = {4},
	pages = {413-22},
	pmc = {PMC3324571},
	pmid = {21515639},
	pst = {ppublish},
	title = {The thing that should not be: predictive coding and the uncanny valley in perceiving human and humanoid robot actions},
	volume = {7},
	year = {2012},
	bdsk-url-1 = {https://doi.org/10.1093/scan/nsr025}}

@article{Thierry2007,
	abstract = {Establishing when and how the human brain differentiates between object categories is key to understanding visual cognition. Event-related potential (ERP) investigations have led to the consensus that faces selectively elicit a negative wave peaking 170 ms after presentation, the 'N170'. In such experiments, however, faces are nearly always presented from a full front view, whereas other stimuli are more perceptually variable, leading to uncontrolled interstimulus perceptual variance (ISPV). Here, we compared ERPs elicited by faces, cars and butterflies while--for the first time--controlling ISPV (low or high). Surprisingly, the N170 was sensitive, not to object category, but to ISPV. In addition, we found category effects independent of ISPV 70 ms earlier than has been generally reported. These results demonstrate early ERP category effects in the visual domain, call into question the face selectivity of the N170 and establish ISPV as a critical factor to control in experiments relying on multitrial averaging.},
	author = {Thierry, Guillaume and Martin, Clara D and Downing, Paul and Pegna, Alan J},
	date-added = {2022-12-29 10:56:15 +0000},
	date-modified = {2022-12-29 10:56:15 +0000},
	doi = {10.1038/nn1864},
	journal = {Nat Neurosci},
	journal-full = {Nature neuroscience},
	mesh = {Adolescent; Adult; Analysis of Variance; Brain Mapping; Electroencephalography; Evoked Potentials, Visual; Female; Humans; Male; Pattern Recognition, Visual; Photic Stimulation; Reaction Time; Spectrum Analysis; Visual Cortex},
	month = {Apr},
	number = {4},
	pages = {505-11},
	pmid = {17334361},
	pst = {ppublish},
	title = {Controlling for interstimulus perceptual variance abolishes N170 face selectivity},
	volume = {10},
	year = {2007},
	bdsk-url-1 = {https://doi.org/10.1038/nn1864}}

@book{Jeffreys1961,
	author = {Jeffreys, H.},
	date-added = {2022-12-27 15:56:46 +0000},
	date-modified = {2022-12-27 16:02:01 +0000},
	edition = {3rd},
	publisher = {Oxford University Press, Clarendon Press},
	title = {Theory of Probability},
	year = {1961}}

@article{Rouder2009,
	abstract = {Progress in science often comes from discovering invariances in relationships among variables; these invariances often correspond to null hypotheses. As is commonly known, it is not possible to state evidence for the null hypothesis in conventional significance testing. Here we highlight a Bayes factor alternative to the conventional t test that will allow researchers to express preference for either the null hypothesis or the alternative. The Bayes factor has a natural and straightforward interpretation, is based on reasonable assumptions, and has better properties than other methods of inference that have been advocated in the psychological literature. To facilitate use of the Bayes factor, we provide an easy-to-use, Web-based program that performs the necessary calculations.},
	author = {Rouder, Jeffrey N and Speckman, Paul L and Sun, Dongchu and Morey, Richard D and Iverson, Geoffrey},
	date-added = {2022-12-27 15:56:30 +0000},
	date-modified = {2022-12-27 15:56:30 +0000},
	doi = {10.3758/PBR.16.2.225},
	journal = {Psychon Bull Rev},
	journal-full = {Psychonomic bulletin \& review},
	mesh = {Analysis of Variance; Bayes Theorem; Data Interpretation, Statistical; Humans; Likelihood Functions; Mathematical Computing; Probability; Psychology, Experimental; Software},
	month = {Apr},
	number = {2},
	pages = {225-37},
	pmid = {19293088},
	pst = {ppublish},
	title = {Bayesian t tests for accepting and rejecting the null hypothesis},
	volume = {16},
	year = {2009},
	bdsk-url-1 = {https://doi.org/10.3758/PBR.16.2.225}}

@article{Kanwisher1997,
	abstract = {Using functional magnetic resonance imaging (fMRI), we found an area in the fusiform gyrus in 12 of the 15 subjects tested that was significantly more active when the subjects viewed faces than when they viewed assorted common objects. This face activation was used to define a specific region of interest individually for each subject, within which several new tests of face specificity were run. In each of five subjects tested, the predefined candidate "face area" also responded significantly more strongly to passive viewing of (1) intact than scrambled two-tone faces, (2) full front-view face photos than front-view photos of houses, and (in a different set of five subjects) (3) three-quarter-view face photos (with hair concealed) than photos of human hands; it also responded more strongly during (4) a consecutive matching task performed on three-quarter-view faces versus hands. Our technique of running multiple tests applied to the same region defined functionally within individual subjects provides a solution to two common problems in functional imaging: (1) the requirement to correct for multiple statistical comparisons and (2) the inevitable ambiguity in the interpretation of any study in which only two or three conditions are compared. Our data allow us to reject alternative accounts of the function of the fusiform face area (area "FF") that appeal to visual attention, subordinate-level classification, or general processing of any animate or human forms, demonstrating that this region is selectively involved in the perception of faces.},
	author = {Kanwisher, N and McDermott, J and Chun, M M},
	date-added = {2022-12-27 09:29:13 +0000},
	date-modified = {2022-12-27 09:29:13 +0000},
	doi = {10.1523/JNEUROSCI.17-11-04302.1997},
	journal = {J Neurosci},
	journal-full = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	mesh = {Adult; Discrimination Learning; Face; Female; Functional Laterality; Humans; Magnetic Resonance Imaging; Male; Pattern Recognition, Visual; Visual Cortex; Visual Pathways; Visual Perception},
	month = {Jun},
	number = {11},
	pages = {4302-11},
	pmc = {PMC6573547},
	pmid = {9151747},
	pst = {ppublish},
	title = {The fusiform face area: a module in human extrastriate cortex specialized for face perception},
	volume = {17},
	year = {1997},
	bdsk-url-1 = {https://doi.org/10.1523/JNEUROSCI.17-11-04302.1997}}

@article{Gauthier2000,
	abstract = {According to modular models of cortical organization, many areas of the extrastriate cortex are dedicated to object categories. These models often assume an early processing stage for the detection of category membership. Can functional imaging isolate areas responsible for detection of members of a category, such as faces or letters? We consider whether responses in three different areas (two selective for faces and one selective for letters) support category detection. Activity in these areas habituates to the repeated presentation of one exemplar more than to the presentation of different exemplars of the same category, but only for the category for which the area is selective. Thus, these areas appear to play computational roles more complex than detection, processing stimuli at the individual level. Drawing from prior work, we suggest that face-selective areas may be involved in the perception of faces at the individual level, whereas letter-selective regions may be tuning themselves to font information in order to recognize letters more efficiently.},
	author = {Gauthier, I and Tarr, M J and Moylan, J and Skudlarski, P and Gore, J C and Anderson, A W},
	date-added = {2022-12-26 21:15:23 +0000},
	date-modified = {2022-12-26 21:15:23 +0000},
	doi = {10.1162/089892900562165},
	journal = {J Cogn Neurosci},
	journal-full = {Journal of cognitive neuroscience},
	mesh = {Adult; Face; Habituation, Psychophysiologic; Humans; Magnetic Resonance Imaging; Pattern Recognition, Visual; Photic Stimulation; Visual Cortex},
	month = {May},
	number = {3},
	pages = {495-504},
	pmid = {10931774},
	pst = {ppublish},
	title = {The fusiform "face area" is part of a network that processes faces at the individual level},
	volume = {12},
	year = {2000},
	bdsk-url-1 = {https://doi.org/10.1162/089892900562165}}

@article{Downing2001,
	abstract = {Despite extensive evidence for regions of human visual cortex that respond selectively to faces, few studies have considered the cortical representation of the appearance of the rest of the human body. We present a series of functional magnetic resonance imaging (fMRI) studies revealing substantial evidence for a distinct cortical region in humans that responds selectively to images of the human body, as compared with a wide range of control stimuli. This region was found in the lateral occipitotemporal cortex in all subjects tested and apparently reflects a specialized neural system for the visual perception of the human body.},
	author = {Downing, P E and Jiang, Y and Shuman, M and Kanwisher, N},
	date-added = {2022-12-26 21:10:35 +0000},
	date-modified = {2022-12-26 21:10:35 +0000},
	doi = {10.1126/science.1063414},
	journal = {Science},
	journal-full = {Science (New York, N.Y.)},
	mesh = {Animals; Brain Mapping; Face; Form Perception; Human Body; Humans; Magnetic Resonance Imaging; Occipital Lobe; Pattern Recognition, Visual; Recognition, Psychology; Temporal Lobe; Visual Cortex},
	month = {Sep},
	number = {5539},
	pages = {2470-3},
	pmid = {11577239},
	pst = {ppublish},
	title = {A cortical area selective for visual processing of the human body},
	volume = {293},
	year = {2001},
	bdsk-url-1 = {https://doi.org/10.1126/science.1063414}}

@article{Hu2020,
	abstract = {The human "person" is a common percept we encounter. Research on person perception has been focused either on face or body perception-with less attention paid to whole person perception. We review psychological and neuroscience studies aimed at understanding how face and body processing operate in concert to support intact person perception. We address this question considering: a.) the task to be accomplished (identification, emotion processing, detection), b.) the neural stage of processing (early/late visual mechanisms), and c.) the relevant brain regions for face/body/person processing. From the psychological perspective, we conclude that the integration of faces and bodies is mediated by the goal of the processing (e.g., emotion analysis, identification, etc.). From the neural perspective, we propose a hierarchical functional neural architecture of face-body integration that retains a degree of separation between the dorsal and ventral visual streams. We argue for two centers of integration: a ventral semantic integration hub that is the result of progressive, posterior-to-anterior, face-body integration; and a social agent integration hub in the dorsal stream STS.},
	author = {Hu, Ying and Baragchizadeh, Asal and O'Toole, Alice J},
	date-added = {2022-12-26 21:09:23 +0000},
	date-modified = {2022-12-26 21:09:23 +0000},
	doi = {10.1016/j.neubiorev.2020.02.021},
	journal = {Neurosci Biobehav Rev},
	journal-full = {Neuroscience and biobehavioral reviews},
	keywords = {Body perception; Face perception; Facial expression; High-level visual perception; Holistic processing; Identity},
	mesh = {Brain; Facial Recognition; Humans; Pattern Recognition, Visual; Social Perception},
	month = {May},
	pages = {472-486},
	pmid = {32088346},
	pst = {ppublish},
	title = {Integrating faces and bodies: Psychological and neural perspectives on whole person perception},
	volume = {112},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1016/j.neubiorev.2020.02.021}}

@article{Smith2019,
	abstract = {Faces transmit a wealth of important social signals. While previous studies have elucidated the network of cortical regions important for perception of facial expression, and the associated temporal components such as the P100, N170 and EPN, it is still unclear how task constraints may shape the representation of facial expression (or other face categories) in these networks. In the present experiment, we used Multivariate Pattern Analysis (MVPA) with EEG to investigate the neural information available across time about two important face categories (expression and identity) when those categories are either perceived under explicit (e.g. decoding facial expression category from the EEG when task is on expression) or incidental task contexts (e.g. decoding facial expression category from the EEG when task is on identity). Decoding of both face categories, across both task contexts, peaked in time-windows spanning 91-170 ms (across posterior electrodes). Peak decoding of expression, however, was not affected by task context whereas peak decoding of identity was significantly reduced under incidental processing conditions. In addition, errors in EEG decoding correlated with errors in behavioral categorization under explicit processing for both expression and identity, however under incidental conditions only errors in EEG decoding of expression correlated with behavior. Furthermore, decoding time-courses and the spatial pattern of informative electrodes showed consistently better decoding of identity under explicit conditions at later-time periods, with weak evidence for similar effects for decoding of expression at isolated time-windows. Taken together, these results reveal differences and commonalities in the processing of face categories under explicit Vs incidental task contexts and suggest that facial expressions are processed to a richer degree under incidental processing conditions, consistent with prior work indicating the relative automaticity by which emotion is processed. Our work further demonstrates the utility in applying multivariate decoding analyses to EEG for revealing the dynamics of face perception.},
	author = {Smith, Fraser W and Smith, Marie L},
	date-added = {2022-12-26 20:02:01 +0000},
	date-modified = {2022-12-26 20:02:01 +0000},
	doi = {10.1016/j.neuroimage.2019.03.065},
	journal = {Neuroimage},
	journal-full = {NeuroImage},
	keywords = {Categorization; EEG; Emotion; Multi-variate pattern analysis; Vision},
	mesh = {Adolescent; Adult; Brain; Electroencephalography; Emotions; Facial Expression; Facial Recognition; Female; Humans; Male; Support Vector Machine; Young Adult},
	month = {Jul},
	pages = {261-271},
	pmid = {30940611},
	pst = {ppublish},
	title = {Decoding the dynamic representation of facial expressions of emotion in explicit and incidental tasks},
	volume = {195},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1016/j.neuroimage.2019.03.065}}

@article{Sanders2018,
	abstract = {Hyper-realistic masks present a new challenge to security and crime prevention. We have recently shown that people's ability to differentiate these masks from real faces is extremely limited. Here we consider individual differences as a means to improve mask detection. Participants categorized single images as masks or real faces in a computer-based task. Experiment 1 revealed poor accuracy (40%) and large individual differences (5-100%) for high-realism masks among low-realism masks and real faces. Individual differences in mask categorization accuracy remained large when the Low-realism condition was eliminated (Experiment 2). Accuracy for mask images was not correlated with accuracy for real face images or with prior knowledge of hyper-realistic face masks. Image analysis revealed that mask and face stimuli were most strongly differentiated in the region below the eyes. Moreover, high-performing participants tracked the differential information in this area, but low-performing participants did not. Like other face tasks (e.g. identification), hyper-realistic mask detection gives rise to large individual differences in performance. Unlike many other face tasks, performance may be localized to a specific image cue.},
	author = {Sanders, Jet G and Jenkins, Rob},
	date-added = {2022-12-26 20:01:45 +0000},
	date-modified = {2022-12-26 20:01:45 +0000},
	doi = {10.1186/s41235-018-0118-3},
	journal = {Cogn Res Princ Implic},
	journal-full = {Cognitive research: principles and implications},
	keywords = {Deception; Disguise; Face detection; Face perception; Face recognition; Fraud; Individual differences; Masks; Passports; Performance enhancement},
	month = {Dec},
	pages = {24},
	pmc = {PMC6019421},
	pmid = {30009254},
	pst = {epublish},
	title = {Individual differences in hyper-realistic mask detection},
	volume = {3},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1186/s41235-018-0118-3}}

@article{Sanders2017,
	author = {Jet Gabrielle Sanders and Yoshiyuki Ueda and Kazusa Minemoto and Eilidh Noyes and Sakiko Yoshikawa and Rob Jenkins},
	date-added = {2022-12-26 19:59:18 +0000},
	date-modified = {2022-12-26 20:02:08 +0000},
	doi = {10.1186/s41235-017-0079-y},
	journal = {Cognitive Research: Principles and Implications},
	month = {oct},
	number = {1},
	publisher = {Springer Science and Business Media {LLC}},
	title = {Hyper-realistic face masks: a new challenge in person identification},
	url = {https://doi.org/10.1186%2Fs41235-017-0079-y},
	volume = {2},
	year = 2017,
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBnLi4vLi4vLi4vLi4vLi4vVm9sdW1lcy9Hb29nbGVEcml2ZS9NeSBEcml2ZS9DdXJyZW50IHdvcmsvUmVzZWFyY2gvdW5jYW5ueXZhbGxleS9wYXBlcnMvU2FuZGVycyAyMDE3LnBkZk8RAeQAAAAAAeQAAgAADEdvb2dsZSBEcml2ZQAAAAAAAAAAAAAAAAAAAI70xwBCRAAB/////xBTYW5kZXJzIDIwMTcucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////13qnMwAAAAAAAAAA/////wAAEgFjdQAAAAAAAAAAAAAAAAAGcGFwZXJzAAIAWi86Vm9sdW1lczpHb29nbGVEcml2ZTpNeSBEcml2ZTpDdXJyZW50IHdvcms6UmVzZWFyY2g6dW5jYW5ueXZhbGxleTpwYXBlcnM6U2FuZGVycyAyMDE3LnBkZgAOACIAEABTAGEAbgBkAGUAcgBzACAAMgAwADEANwAuAHAAZABmAA8AGgAMAEcAbwBvAGcAbABlACAARAByAGkAdgBlABIARS9NeSBEcml2ZS9DdXJyZW50IHdvcmsvUmVzZWFyY2gvdW5jYW5ueXZhbGxleS9wYXBlcnMvU2FuZGVycyAyMDE3LnBkZgAAEwAUL1ZvbHVtZXMvR29vZ2xlRHJpdmUACQA3ADdjaWZzAAABAAAAc21iOi8vRFJJVkVAMTI3LjAuMC4xOjU5MTQ4L0dvb2dsZSUyMERyaXZlAAD//wAAAAgADQAaACQAjgAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAJ2}}

@article{Mori1970,
	author = {Mori, Masahiro},
	date-added = {2022-12-26 19:51:51 +0000},
	date-modified = {2022-12-26 19:52:29 +0000},
	journal = {Energy},
	pages = {33-35},
	title = {The Uncanny Valley},
	volume = {7},
	year = {1970}}

@article{Mori2012,
	author = {Mori, Masahiro and MacDorman, Karl F. and Kageki, Norri},
	date-added = {2022-12-26 19:50:43 +0000},
	date-modified = {2022-12-26 19:51:39 +0000},
	doi = {10.1109/MRA.2012.2192811},
	journal = {IEEE Robotics & Automation Magazine},
	number = {2},
	pages = {98-100},
	title = {The Uncanny Valley [From the Field]},
	volume = {19},
	year = {2012},
	bdsk-url-1 = {https://doi.org/10.1109/MRA.2012.2192811}}

@article{Urgen2018,
	abstract = {Uncanny valley refers to humans' negative reaction to almost-but-not-quite-human agents. Theoretical work proposes prediction violation as an explanation for uncanny valley but no empirical work has directly tested it. Here, we provide evidence that supports this theory using event-related brain potential recordings from the human scalp. Human subjects were presented images and videos of three agents as EEG was recorded: a real human, a mechanical robot, and a realistic robot in between. The real human and the mechanical robot had congruent appearance and motion whereas the realistic robot had incongruent appearance and motion. We hypothesize that the appearance of the agent would provide a context to predict her movement, and accordingly the perception of the realistic robot would elicit an N400 effect indicating the violation of predictions, whereas the human and the mechanical robot would not. Our data confirmed this hypothesis suggesting that uncanny valley could be explained by violation of one's predictions about human norms when encountered with realistic but artificial human forms. Importantly, our results implicate that the mechanisms underlying perception of other individuals in our environment are predictive in nature.},
	author = {Urgen, Burcu A and Kutas, Marta and Saygin, Ayse P},
	date-added = {2022-12-26 18:10:15 +0000},
	date-modified = {2022-12-26 18:10:15 +0000},
	doi = {10.1016/j.neuropsychologia.2018.04.027},
	journal = {Neuropsychologia},
	journal-full = {Neuropsychologia},
	keywords = {Action perception; N400; Predictive processing; Social neuroscience; Uncanny valley},
	mesh = {Adult; Brain; Brain Mapping; Electroencephalography; Evoked Potentials; Female; Humans; Male; Motion; Pattern Recognition, Visual; Photic Stimulation; Robotics; Social Perception; Young Adult},
	month = {Jun},
	pages = {181-185},
	pmc = {PMC6556781},
	pmid = {29704523},
	pst = {ppublish},
	title = {Uncanny valley as a window into predictive processing in the social brain},
	volume = {114},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1016/j.neuropsychologia.2018.04.027}}
